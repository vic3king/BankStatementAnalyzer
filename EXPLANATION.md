Welcome to Bank Statement Analyser

Thank you for sharing this assessment. I have thoroughly enjoyed building it, as it touches on some of my core skills and is very relatable.
And without further ado, please find a detailed report on my thinking and decision-making for this assessment.

To kick things off, I did a complete system design to document my architecture and thinking, you can view the link here. But in summary, this is what I planned to achieve.

I call API one (POST /v1/api/parse-bank-statement) with a PDF file, and it adds a job to my Bull queue. The Bull queue in tooling requires a Redis instance or connection to work (I will provide one for easy testing). When a job is added to the queue, the consumer receives it and goes through three key processes: (1) extract (PDF to text), (2) process (LLM), and (3) reconciliation validation based on the difference between the start and end balance and the sum of all the transactions. When the job is done, I use the second API (GET /v1/api/parse-bank-statement/job/<job-id>) to check the job status before sending the result back to the client. The client tracks job status by implementing a long poll that keeps checking and returning updates from the server with granular progress like 25, 55, etc. Once complete, data is displayed. On the frontend, users can decide to upload one or more files using either the click-and-upload or drag-and-drop option. After processing, all details are shown on the right side when you expand the accordion.

Technical decisions
My goal was to fulfil my functional requirements and then focus on achieving non-functional requirements like low latency and a reactive API, which influenced my choice of tools.

I used NestJS, a TypeScript framework, on the backend because I was able to bootstrap quickly, maintain a clean and consistent codebase that could scale and be maintained long-term, and set us up for a potential switch to a microservice architecture. NestJS uses modules, and each module could become an independent service. It meant I was able to build quickly thus how I ended up building the queuing system for analyzing data. This means users get quick feedback, are not stuck waiting too long, receive granular responses on progress, and can handle multiple files where each file is treated independently, including error tracking.

I went with the OpenAI GPT-4o model and the Chat Completion API for my LLM, and I made the decision not to build a RAG system, as that’s something I’ve used in the past and, due to my knowledge, I would have wanted to spend more time tooling it properly. So, my current implementation converts PDF to text and uses it as part of the prompt for the LLM. This is a potential bottleneck in the system, and if you’re wondering why, well, think token management! LLMs are capped, and depending on how big the PDF is, I might run out of context. To mitigate this a little, I’ve validated and kept my PDF sizes small. In the future, we can improve this system.

I also built an LLM interface leveraging my experience in OOP. This interface helps my codebase stay agnostic to who my LLM provider is. This is helpful as we can easily change providers and implementation logic, and we can also build with multiple providers in mind. This could also be integrated in the future with tools like Vellum to make things even better.

On the frontend, I went with Next.js because it gives me excellent TypeScript support, a great developer experience with hot reloading, and a modern React framework with the App Router. The structure is a simple setup with a few components, including a drag-and-drop FileUploader for PDF uploads, a File component that displays upload progress and status with real-time polling, a collapsible ResultsView component that presents parsed bank statement data in an organized format with account details and transaction lists, and a clean dashboard layout that separates the upload queue from processed documents. The architecture uses React hooks for state management, implements real-time job polling to track processing status, and provides a responsive design that handles file uploads, processing workflows, and data visualization seamlessly.
In the future, we could return a custom name for the PDF, which would improve the visual experience. We could also add authentication and authorization, tracking of analyzed PDFs per user, and support for more file types. Containerizing the application and deploying it would also be a strong step toward production readiness. Future frontend improvements could include allowing users to retry failed uploads directly from the interface. Currently, when users upload the same file twice, we need to either permit duplicate uploads or implement a functional retry button on the documents (which is currently non-functional)